"use client"

/**
 * @description ì˜ì–´ë¥¼ í•œêµ­ì–´ë¡œ ë²ˆì—­í•˜ëŠ” ê¸°ëŠ¥ìœ¼ë¡œ ê°„ë‹¨í•œ LLM ì•± êµ¬í˜„
 */

import {ChatOpenAI} from "@langchain/openai";
import {ChatPromptTemplate} from "@langchain/core/prompts";
import { useEffect, useState } from "react";
import { ChatPromptValueInterface } from "@langchain/core/prompt_values";
import { Textarea } from "@/components/ui/textarea";
import { Button } from "@/components/ui/button";

// ëª¨ë¸ ìƒì„±
const model = new ChatOpenAI({
    model: "gpt-4o-mini",
    openAIApiKey: process.env["NEXT_PUBLIC_OPENAI_API_KEY"],
});

// const client = wrapOpenAI(new OpenAI());

export default function Page(){
    const [answer,setAnswer] = useState("");
    const [answerStream,setAnswerStream] = useState("");
    const [english,setEnglish] = useState("");
    const [language,setLanguage] = useState("í•œêµ­ì–´");
    // const messages = [
    //     new SystemMessage("ì˜ì–´ë¥¼ í•œêµ­ì–´ë¡œ ë²ˆì—­í•´ì¤˜."),
    //     new HumanMessage("Hello, world! Nice to meet you. My name is Bo."),
    // ]


    useEffect(()=>{
        // invoke();
        // stream();
        // promptTemplate();
    },[])

    // í•œë²ˆì— ê°€ì ¸ì˜¤ëŠ” ë°©ì‹
    const invoke = async (messages:ChatPromptValueInterface) =>{
        const res = await model.invoke(messages);
        console.log(res);
        setAnswer(res.content.toString());
        return res;
    }

    // ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹
    const stream = async (messages:ChatPromptValueInterface) =>{
        const stream = await model.stream(messages);
        const chunks = [];
        for await(const chunk of stream){
            chunks.push(chunk.content);
            setAnswerStream(chunks.join(""));
        }
    }

    // í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ë°©ì‹
    const promptTemplate = async () =>{
        const prompt = ChatPromptTemplate.fromMessages([
            ["system", "ì˜ì–´ë¥¼ {language}ë¡œ ë²ˆì—­í•´ì¤˜."],
            ["user", "{text}"],
        ]);

        const promptValue = await prompt.invoke({
            language: language,
            text: english,
        });
        console.log(promptValue);
        await invoke(promptValue);
        await stream(promptValue);
        // setAnswer(promptValue.toString());
    }

    return (
        <div>
            <div>
                <h1 className="text-2xl font-bold">Build a simple LLM application with chat models and prompt templates</h1>
                <p>ğŸ’¡ invoke ë°©ì‹ì€ í•œë²ˆì— ê°€ì ¸ì˜¤ëŠ” ë°©ì‹ì´ê³ , stream ë°©ì‹ì€ ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ì…ë‹ˆë‹¤.</p>
                <p>ğŸ’¡ system promptëŠ” ëª¨ë¸ì˜ í–‰ë™ì„ ì •ì˜í•˜ëŠ” í”„ë¡¬í”„íŠ¸</p>
                <p>ğŸ’¡ promptë¥¼ templateí™” í•˜ì—¬ í”„ë¡¬í”„íŠ¸ì˜ êµ¬ì¡°ë¥¼ ë³€ìˆ˜ë¡œ í…œí”Œë¦¿í™” í•¨</p>

            </div>
            <div className="mt-8 border-2 border-gray-300 rounded-md p-4">
                <h1 className="text-xl font-bold">ì‹¤ìŠµ ê²°ê³¼</h1>
                <Textarea
                    placeholder="Enter your text"
                    value={english}
                    onChange={(e) => setEnglish(e.target.value)}
                />
                <select value={language} onChange={(e) => setLanguage(e.target.value)}>
                    <option value="í•œêµ­ì–´">í•œêµ­ì–´</option>
                    <option value="ì¼ë³¸ì–´">ì¼ë³¸ì–´</option>
                </select>
                <Button onClick={() => promptTemplate()}>ë²ˆì—­í•˜ê¸°</Button>

                <div className="flex mt-6">
                    <div>
                        <h1 className="text-lg font-bold">invoke ë°©ì‹</h1>
                        <div>{answer}</div>
                    </div>
                    <div>
                        <h1 className="text-lg font-bold">stream ë°©ì‹</h1>
                        <div>{answerStream}</div>
                    </div>
                </div>
            </div>
            
        </div>
    )
}